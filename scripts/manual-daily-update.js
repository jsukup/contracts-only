#!/usr/bin/env node
/**
 * ContractsOnly Manual Daily Update Script
 * 
 * A streamlined script for manual daily job management that:
 * 1. Scrapes new jobs from multiple sources
 * 2. Cleans up stale jobs
 * 3. Generates daily reports
 * 4. Provides clear progress and results
 * 
 * Usage: node scripts/manual-daily-update.js [--dry-run] [--limit=N] [--skip-cleanup]
 */

const JobSeeder = require('./job-seeder.js');
const StaleJobCleaner = require('./stale-job-cleanup.js');
const DailyReportGenerator = require('./daily-report-generator.js');

class ManualDailyUpdate {
  constructor(options = {}) {
    this.dryRun = options.dryRun || false;
    this.limit = parseInt(options.limit) || 100;
    this.skipCleanup = options.skipCleanup || false;
    this.startTime = new Date();
    this.results = {
      scraping: null,
      cleanup: null,
      report: null,
      summary: {}
    };
  }

  /**
   * Main execution method
   */
  async run() {
    console.log('ğŸš€ ContractsOnly Manual Daily Update');
    console.log('=====================================');
    console.log(`Mode: ${this.dryRun ? 'ğŸ§ª DRY RUN' : 'ğŸ”´ LIVE UPDATE'}`);
    console.log(`Job Limit: ${this.limit} jobs`);
    console.log(`Started: ${this.startTime.toLocaleTimeString()}\n`);

    try {
      // Step 1: Job Scraping
      await this.runJobScraping();
      
      // Step 2: Stale Job Cleanup (optional)
      if (!this.skipCleanup) {
        await this.runStaleJobCleanup();
      }
      
      // Step 3: Generate Daily Report
      await this.generateDailyReport();
      
      // Step 4: Show Summary
      this.showFinalSummary();
      
    } catch (error) {
      this.handleError(error);
    }
  }

  /**
   * Run job scraping process
   */
  async runJobScraping() {
    console.log('ğŸ“¡ STEP 1: Scraping New Jobs');
    console.log('â”€'.repeat(40));
    
    const stepStart = Date.now();
    
    try {
      const seeder = new JobSeeder({
        dryRun: this.dryRun,
        limit: this.limit
      });
      
      await seeder.run();
      
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.scraping = {
        status: 'success',
        duration,
        jobsScraped: seeder.scrapedJobs.length,
        jobsImported: seeder.importedJobs.length,
        duplicates: seeder.duplicateJobs.length,
        rejected: seeder.rejectedJobs.length
      };
      
      console.log(`âœ… Job scraping completed in ${duration}s`);
      console.log(`   ğŸ“Š Results: ${seeder.importedJobs.length} imported, ${seeder.duplicateJobs.length} duplicates, ${seeder.rejectedJobs.length} rejected\n`);
      
    } catch (error) {
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.scraping = {
        status: 'failed',
        duration,
        error: error.message
      };
      
      console.log(`âŒ Job scraping failed after ${duration}s: ${error.message}\n`);
      // Continue with other steps even if scraping fails
    }
  }

  /**
   * Run stale job cleanup process
   */
  async runStaleJobCleanup() {
    console.log('ğŸ§¹ STEP 2: Cleaning Stale Jobs');
    console.log('â”€'.repeat(40));
    
    const stepStart = Date.now();
    
    try {
      const cleaner = new StaleJobCleaner({
        dryRun: this.dryRun,
        days: 30,
        batchSize: 50 // Smaller batch for manual runs
      });
      
      await cleaner.run();
      
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.cleanup = {
        status: 'success',
        duration,
        jobsCleaned: cleaner.stats.cleaned,
        staleJobs: cleaner.stats.stale,
        invalidUrls: cleaner.stats.invalidUrl,
        totalProcessed: cleaner.cleanedJobs.length
      };
      
      console.log(`âœ… Cleanup completed in ${duration}s`);
      console.log(`   ğŸ—‘ï¸  Results: ${cleaner.stats.cleaned} cleaned, ${cleaner.stats.stale} stale, ${cleaner.stats.invalidUrl} invalid URLs\n`);
      
    } catch (error) {
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.cleanup = {
        status: 'failed',
        duration,
        error: error.message
      };
      
      console.log(`âŒ Cleanup failed after ${duration}s: ${error.message}\n`);
    }
  }

  /**
   * Generate daily report
   */
  async generateDailyReport() {
    console.log('ğŸ“Š STEP 3: Generating Daily Report');
    console.log('â”€'.repeat(40));
    
    const stepStart = Date.now();
    
    try {
      const generator = new DailyReportGenerator({
        date: new Date(),
        format: 'both'
      });
      
      await generator.generateReport();
      
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.report = {
        status: 'success',
        duration,
        generated: true
      };
      
      const reportDate = new Date().toISOString().split('T')[0];
      console.log(`âœ… Report generated in ${duration}s`);
      console.log(`   ğŸ“„ Files: daily-report-${reportDate}.json, daily-report-${reportDate}.md\n`);
      
    } catch (error) {
      const duration = Math.round((Date.now() - stepStart) / 1000);
      
      this.results.report = {
        status: 'failed',
        duration,
        error: error.message
      };
      
      console.log(`âŒ Report generation failed after ${duration}s: ${error.message}\n`);
    }
  }

  /**
   * Show final summary
   */
  showFinalSummary() {
    const totalDuration = Math.round((Date.now() - this.startTime.getTime()) / 1000);
    const hasErrors = this.hasErrors();
    
    console.log('ğŸ¯ SUMMARY');
    console.log('â•'.repeat(50));
    console.log(`â±ï¸  Total Time: ${totalDuration}s (${Math.round(totalDuration/60)}m ${totalDuration%60}s)`);
    console.log(`ğŸ® Mode: ${this.dryRun ? 'DRY RUN' : 'LIVE UPDATE'}`);
    console.log(`ğŸ“ˆ Status: ${hasErrors ? 'âš ï¸  Completed with warnings' : 'âœ… Success'}`);
    
    // Job scraping summary
    if (this.results.scraping?.status === 'success') {
      console.log(`ğŸ“¡ Scraping: âœ… ${this.results.scraping.jobsImported} new jobs imported`);
    } else if (this.results.scraping?.status === 'failed') {
      console.log(`ğŸ“¡ Scraping: âŒ Failed - ${this.results.scraping.error}`);
    }
    
    // Cleanup summary
    if (this.results.cleanup?.status === 'success') {
      console.log(`ğŸ§¹ Cleanup: âœ… ${this.results.cleanup.jobsCleaned} jobs cleaned`);
    } else if (this.results.cleanup?.status === 'failed') {
      console.log(`ğŸ§¹ Cleanup: âŒ Failed - ${this.results.cleanup.error}`);
    } else if (this.skipCleanup) {
      console.log(`ğŸ§¹ Cleanup: â­ï¸  Skipped as requested`);
    }
    
    // Report summary
    if (this.results.report?.status === 'success') {
      console.log(`ğŸ“Š Report: âœ… Daily report generated`);
    } else if (this.results.report?.status === 'failed') {
      console.log(`ğŸ“Š Report: âŒ Failed - ${this.results.report.error}`);
    }
    
    console.log('â•'.repeat(50));
    
    // Next steps recommendations
    this.showRecommendations();
  }

  /**
   * Show actionable recommendations
   */
  showRecommendations() {
    const recommendations = [];
    
    // Check results and provide recommendations
    if (this.results.scraping?.status === 'success') {
      const imported = this.results.scraping.jobsImported;
      const duplicates = this.results.scraping.duplicates;
      
      if (imported === 0) {
        recommendations.push('ğŸ” No new jobs found. Try running again later or check source websites.');
      } else if (imported < 10) {
        recommendations.push(`ğŸ“ˆ Only ${imported} new jobs imported. Consider increasing --limit or running more frequently.`);
      } else {
        recommendations.push(`ğŸ‰ Great! ${imported} new jobs added to the platform.`);
      }
      
      if (duplicates > imported * 0.5) {
        recommendations.push('ğŸ”„ High duplicate rate suggests frequent scraping. Consider running less often.');
      }
    }
    
    if (this.results.cleanup?.status === 'success' && this.results.cleanup.jobsCleaned > 0) {
      recommendations.push(`ğŸ§¹ Cleaned ${this.results.cleanup.jobsCleaned} stale jobs. Database is optimized.`);
    }
    
    if (this.results.report?.status === 'success') {
      const reportDate = new Date().toISOString().split('T')[0];
      recommendations.push(`ğŸ“Š Review your daily report: reports/daily-report-${reportDate}.md`);
    }
    
    if (recommendations.length > 0) {
      console.log('ğŸ’¡ RECOMMENDATIONS:');
      recommendations.forEach(rec => console.log(`   ${rec}`));
    }
    
    console.log('\nğŸš€ Daily update complete! Run again tomorrow or as needed.');
  }

  /**
   * Check if there were any errors
   */
  hasErrors() {
    return this.results.scraping?.status === 'failed' || 
           this.results.cleanup?.status === 'failed' || 
           this.results.report?.status === 'failed';
  }

  /**
   * Handle fatal errors
   */
  handleError(error) {
    const duration = Math.round((Date.now() - this.startTime.getTime()) / 1000);
    
    console.error('\nğŸ’¥ FATAL ERROR');
    console.error('â•'.repeat(50));
    console.error(`â±ï¸  Duration: ${duration}s`);
    console.error(`âŒ Error: ${error.message}`);
    console.error('â•'.repeat(50));
    console.error('\nğŸ”§ Troubleshooting:');
    console.error('   â€¢ Check your internet connection');
    console.error('   â€¢ Verify Python environment: job-scraper-env/');
    console.error('   â€¢ Check .env file for correct database credentials');
    console.error('   â€¢ Try running with --dry-run to test');
    
    process.exit(1);
  }
}

// CLI execution
async function main() {
  const args = process.argv.slice(2);
  
  const options = {
    dryRun: args.includes('--dry-run'),
    limit: args.find(arg => arg.startsWith('--limit='))?.split('=')[1],
    skipCleanup: args.includes('--skip-cleanup')
  };
  
  const updater = new ManualDailyUpdate(options);
  await updater.run();
}

// Show help if requested
if (process.argv.includes('--help') || process.argv.includes('-h')) {
  console.log(`
ContractsOnly Manual Daily Update Script

Usage:
  node scripts/manual-daily-update.js [options]

Options:
  --dry-run         Test mode - no database changes
  --limit=N         Number of jobs to scrape (default: 100)
  --skip-cleanup    Skip stale job cleanup
  --help, -h        Show this help message

Examples:
  node scripts/manual-daily-update.js                    # Normal daily run
  node scripts/manual-daily-update.js --dry-run          # Test run
  node scripts/manual-daily-update.js --limit=50         # Scrape 50 jobs
  node scripts/manual-daily-update.js --skip-cleanup     # Skip cleanup step
`);
  process.exit(0);
}

// Run if called directly
if (require.main === module) {
  main().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

module.exports = ManualDailyUpdate;